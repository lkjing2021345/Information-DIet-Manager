# fetch_data.py 功能开发计划

## 功能列表

| 功能编号 | 功能描述 | 需要实现的函数 | 涉及的库函数 |
|---------|---------|--------------|------------|
| 1 | 错误处理完善 | `safe_extract_history()`, `validate_data()` | `logging`, `try-except` |
| 2 | 日期范围过滤 | `filter_by_date_range()` | `datetime.datetime`, `pandas.DataFrame.query()` |
| 3 | 数据去重 | `remove_duplicates()` | `pandas.DataFrame.drop_duplicates()` |
| 7 | 增量更新 | `get_last_sync_time()`, `incremental_extract()` | `json.dump()`, `json.load()`, `datetime` |
| 8 | 多浏览器支持 | `get_edge_history_path()`, `get_firefox_history_path()`, `extract_history_by_browser()` | `os.path.exists()`, `sqlite3` |
| 9 | 数据统计功能 | `calculate_visit_duration()`, `analyze_frequency()`, `generate_statistics()` | `pandas.groupby()`, `pandas.agg()` |
| 11 | 时区自动调整 | `get_local_timezone()`, `convert_to_local_time()` | `datetime.timezone`, `time.timezone` |
| 12 | 多格式导出 | `save_as_json()`, `save_as_excel()`, `export_data()` | `json.dump()`, `pandas.to_excel()`, `pandas.to_json()` |

---

## 详细实现说明

### 功能 1: 错误处理完善

**需要实现的函数:**
- `safe_extract_history()` - 带完整错误处理的历史记录提取
- `validate_data(df)` - 验证数据有效性

**涉及的库函数:**

#### 1.1 logging 模块
```python
import logging

# 基本配置
logging.basicConfig(
    level=logging.INFO,  # 日志级别: DEBUG, INFO, WARNING, ERROR, CRITICAL
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),  # 输出到文件
        logging.StreamHandler()  # 输出到控制台
    ]
)

# 使用方法
logger = logging.getLogger(__name__)
logger.info("信息日志")
logger.warning("警告日志")
logger.error("错误日志")
logger.exception("异常日志，会自动记录堆栈信息")
```

#### 1.2 异常处理
```python
try:
    # 可能出错的代码
    result = risky_operation()
except FileNotFoundError as e:
    logger.error(f"文件未找到: {e}")
except PermissionError as e:
    logger.error(f"权限错误: {e}")
except sqlite3.Error as e:
    logger.error(f"数据库错误: {e}")
except Exception as e:
    logger.exception(f"未知错误: {e}")
finally:
    # 清理代码
    cleanup()
```

---

### 功能 2: 日期范围过滤

**需要实现的函数:**
- `filter_by_date_range(df, start_date=None, end_date=None, days=None)`

**涉及的库函数:**

#### 2.1 datetime 模块
```python
from datetime import datetime, timedelta

# 获取当前时间
now = datetime.now()

# 计算过去N天
days_ago = now - timedelta(days=7)

# 字符串转日期
date_str = "2026-02-16"
date_obj = datetime.strptime(date_str, "%Y-%m-%d")

# 日期转字符串
date_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
```

#### 2.2 pandas 日期过滤
```python
import pandas as pd

# 方法1: 使用布尔索引
filtered_df = df[df['visit_time'] >= start_date]
filtered_df = df[(df['visit_time'] >= start_date) & (df['visit_time'] <= end_date)]

# 方法2: 使用 query 方法
filtered_df = df.query('visit_time >= @start_date and visit_time <= @end_date')

# 方法3: 使用 between
filtered_df = df[df['visit_time'].between(start_date, end_date)]
```

---

### 功能 3: 数据去重

**需要实现的函数:**
- `remove_duplicates(df, subset=None, keep='last')`

**涉及的库函数:**

#### 3.1 pandas.DataFrame.drop_duplicates()
```python
# 基本用法
df_unique = df.drop_duplicates()

# 指定列去重
df_unique = df.drop_duplicates(subset=['url', 'visit_time'])

# 保留策略
df_unique = df.drop_duplicates(keep='first')   # 保留第一次出现
df_unique = df.drop_duplicates(keep='last')    # 保留最后一次出现
df_unique = df.drop_duplicates(keep=False)     # 删除所有重复项

# 原地修改
df.drop_duplicates(inplace=True)
```

---

### 功能 7: 增量更新

**需要实现的函数:**
- `get_last_sync_time(config_file)` - 读取上次同步时间
- `save_sync_time(config_file, timestamp)` - 保存同步时间
- `incremental_extract(last_sync_time)` - 增量提取

**涉及的库函数:**

#### 7.1 json 模块
```python
import json

# 写入 JSON
data = {'last_sync': '2026-02-16 10:00:00', 'count': 100}
with open('config.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, indent=4, ensure_ascii=False)

# 读取 JSON
with open('config.json', 'r', encoding='utf-8') as f:
    data = json.load(f)
    last_sync = data.get('last_sync')

# 处理不存在的文件
import os
if os.path.exists('config.json'):
    with open('config.json', 'r') as f:
        data = json.load(f)
else:
    data = {}
```

#### 7.2 时间戳转换
```python
from datetime import datetime

# datetime 转时间戳
timestamp = datetime.now().timestamp()

# 时间戳转 datetime
dt = datetime.fromtimestamp(timestamp)

# datetime 转字符串
time_str = datetime.now().isoformat()  # ISO 8601 格式

# 字符串转 datetime
dt = datetime.fromisoformat('2026-02-16T10:00:00')
```

---

### 功能 8: 多浏览器支持

**需要实现的函数:**
- `get_edge_history_path()` - 获取 Edge 历史路径
- `get_firefox_history_path()` - 获取 Firefox 历史路径
- `extract_history_by_browser(browser_name)` - 按浏览器提取

**涉及的库函数:**

#### 8.1 浏览器路径
```python
import os
import sys

# Edge 路径
if sys.platform == 'win32':
    edge_path = os.path.expanduser(r"~\AppData\Local\Microsoft\Edge\User Data\Default\History")
elif sys.platform == 'darwin':
    edge_path = os.path.expanduser(r"~/Library/Application Support/Microsoft Edge/Default/History")

# Firefox 路径 (需要查找 profiles.ini)
if sys.platform == 'win32':
    firefox_base = os.path.expanduser(r"~\AppData\Roaming\Mozilla\Firefox\Profiles")
elif sys.platform == 'darwin':
    firefox_base = os.path.expanduser(r"~/Library/Application Support/Firefox/Profiles")

# 检查文件是否存在
if os.path.exists(path):
    print(f"找到文件: {path}")
```

#### 8.2 Firefox 数据库查询
```python
# Firefox 使用 places.sqlite，表结构不同
query = """
SELECT
    moz_places.url,
    moz_places.title,
    moz_places.visit_count,
    moz_historyvisits.visit_date
FROM moz_places
INNER JOIN moz_historyvisits ON moz_places.id = moz_historyvisits.place_id
WHERE moz_historyvisits.visit_date > 0
"""
```

---

### 功能 9: 数据统计功能

**需要实现的函数:**
- `calculate_visit_duration(df)` - 计算访问时长
- `analyze_frequency(df)` - 分析访问频率
- `generate_statistics(df)` - 生成统计报告

**涉及的库函数:**

#### 9.1 pandas.groupby()
```python
# 按域名分组统计
domain_stats = df.groupby('domain').agg({
    'visit_count': 'sum',      # 总访问次数
    'visit_time': 'count',     # 访问记录数
    'url': 'nunique'           # 唯一URL数
})

# 多列分组
hourly_domain = df.groupby(['hour', 'domain']).size()

# 自定义聚合函数
def custom_agg(series):
    return series.max() - series.min()

result = df.groupby('domain')['visit_time'].agg(custom_agg)
```

#### 9.2 时间差计算
```python
# 按域名排序后计算时间差
df_sorted = df.sort_values(['domain', 'visit_time'])
df_sorted['time_diff'] = df_sorted.groupby('domain')['visit_time'].diff()

# 转换为秒
df_sorted['duration_seconds'] = df_sorted['time_diff'].dt.total_seconds()

# 统计平均停留时间
avg_duration = df_sorted.groupby('domain')['duration_seconds'].mean()
```

#### 9.3 频率分析
```python
# 每日访问频率
df['date'] = df['visit_time'].dt.date
daily_freq = df.groupby(['domain', 'date']).size()

# 访问间隔
df_sorted = df.sort_values('visit_time')
df_sorted['visit_interval'] = df_sorted['visit_time'].diff()

# 描述性统计
stats = df['visit_count'].describe()  # count, mean, std, min, 25%, 50%, 75%, max
```

---

### 功能 11: 时区自动调整

**需要实现的函数:**
- `get_local_timezone()` - 获取本地时区
- `convert_to_local_time(df)` - 转换为本地时间

**涉及的库函数:**

#### 11.1 time.timezone
```python
import time
from datetime import timezone, timedelta

# 获取本地时区偏移（秒）
local_offset_seconds = -time.timezone  # 注意是负数
if time.daylight:
    local_offset_seconds = -time.altzone  # 夏令时

# 转换为小时
local_offset_hours = local_offset_seconds / 3600

# 创建时区对象
local_tz = timezone(timedelta(seconds=local_offset_seconds))
```

#### 11.2 datetime 时区处理
```python
from datetime import datetime, timezone, timedelta

# 创建带时区的时间
utc_time = datetime.now(timezone.utc)

# 转换时区
local_tz = timezone(timedelta(hours=8))  # 东八区
local_time = utc_time.astimezone(local_tz)

# pandas 时区转换
df['visit_time'] = pd.to_datetime(df['visit_time'], utc=True)
df['visit_time'] = df['visit_time'].dt.tz_convert('Asia/Shanghai')

# 或者使用偏移
df['visit_time'] = df['visit_time'] + timedelta(hours=local_offset_hours)
```

---

### 功能 12: 多格式导出

**需要实现的函数:**
- `save_as_json(df, output_path)` - 导出为 JSON
- `save_as_excel(df, output_path)` - 导出为 Excel
- `export_data(df, output_path, format='csv')` - 统一导出接口

**涉及的库函数:**

#### 12.1 pandas.to_json()
```python
# 基本用法
df.to_json('output.json')

# 指定格式
df.to_json('output.json', orient='records', indent=4)
# orient 选项:
# - 'records': [{col1: val1, col2: val2}, ...]
# - 'index': {index: {col1: val1, col2: val2}}
# - 'columns': {col1: {index: val1}, col2: {index: val2}}
# - 'values': [[val1, val2], ...]
# - 'split': {'index': [...], 'columns': [...], 'data': [...]}

# 日期格式
df.to_json('output.json', date_format='iso')  # ISO 8601 格式
df.to_json('output.json', date_format='epoch')  # Unix 时间戳

# 中文支持
df.to_json('output.json', force_ascii=False)
```

#### 12.2 pandas.to_excel()
```python
# 需要安装: pip install openpyxl

# 基本用法
df.to_excel('output.xlsx', index=False)

# 指定 sheet 名称
df.to_excel('output.xlsx', sheet_name='历史记录', index=False)

# 多个 sheet
with pd.ExcelWriter('output.xlsx') as writer:
    df1.to_excel(writer, sheet_name='原始数据', index=False)
    df2.to_excel(writer, sheet_name='统计数据', index=False)

# 自定义格式
df.to_excel('output.xlsx',
            index=False,
            freeze_panes=(1, 0),  # 冻结首行
            engine='openpyxl')
```

#### 12.3 pandas.to_csv()
```python
# 完整参数示例
df.to_csv('output.csv',
          index=False,              # 不保存索引
          encoding='utf-8-sig',     # 支持中文，Excel 可正常打开
          sep=',',                  # 分隔符
          na_rep='',                # 空值表示
          date_format='%Y-%m-%d %H:%M:%S')  # 日期格式
```

---

## 推荐的项目结构

```
src/lsj/src/utils/
├── fetch_data.py          # 主文件
├── config.json            # 配置文件（增量更新记录）
├── browser_paths.py       # 浏览器路径管理（可选）
└── data_processor.py      # 数据处理工具（可选）
```

---

## 需要安装的依赖

```bash
pip install pandas openpyxl matplotlib
```

---

## 实现顺序建议

1. **功能 1** (错误处理) - 先完善基础，后续功能都依赖它
2. **功能 11** (时区调整) - 修改现有的时间处理逻辑
3. **功能 3** (数据去重) - 简单且独立
4. **功能 2** (日期过滤) - 为增量更新做准备
5. **功能 7** (增量更新) - 依赖日期过滤
6. **功能 12** (多格式导出) - 修改现有导出逻辑
7. **功能 9** (数据统计) - 增强分析功能
8. **功能 8** (多浏览器) - 最复杂，最后实现

---

## 注意事项

1. **Firefox 数据库** 可能被锁定，需要复制后读取（与 Chrome 相同）
2. **时间戳格式** Chrome 和 Firefox 不同：
   - Chrome: WebKit 时间戳（从 1601-01-01 开始的微秒数）
   - Firefox: Unix 时间戳（从 1970-01-01 开始的微秒数）
3. **增量更新** 需要记录上次同步的最大时间戳
4. **Excel 导出** 需要安装 `openpyxl` 库
5. **时区处理** 建议使用 `time.timezone` 而不是硬编码